""" Reference
    1. http://solarisailab.com/archives/2482
    2. CS/ML/Lab/GAN/Bayesian/gab mnist tensorflow
"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import os

import tensorflow as tf


import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)


# Function to plot an MNIST image generated
#   - plot 8*8 images
def plot_generated_mnist_images(samples):
    fig = plt.figure(figsize=(8, 8));
    gs = gridspec.GridSpec(8, 8);
    gs.update(wspace=0.05, hspace=0.05);

    for i, sample in enumerate(samples):
        ax = plt.subplot(gs[i]);
        plt.axis("off");
        plt.imshow(sample.reshape(28, 28));

    return fig;



#os.environ['CUDA_VISIBLE_DEVICES'] = '-1';



def GAN_TRAIN_MNIST():
    """ Set the training data==MNIST """
    warnings.simplefilter(action='ignore', category=FutureWarning);
    from tensorflow.examples.tutorials.mnist import input_data
    mnist = input_data.read_data_sets("./mnist/data/", one_hot=True);

    """ Set the path to save the result"""
    data = "test/MNIST/"
    path = "./GAN/myGAN/"+data;
    model_path = path+"model/";
    fig_path = path+"image/";


    """ Set the hyper-parameters """
    num_epochs = 50;
    batch_size = 100;
    batch_num = 600;

    image_size = 28*28;         # the size of an image generated(or real data == mnist image)
    n_hidden1 = 256;             # the number of neurons in a hidden layer
    n_hidden2 = 512;
    n_hidden3 = 1024;
    noise_size = 128;           # the size of input noise on the generator


    learning_rate = 0.0002;     # learning rate for an optimizer


    """ Set the placeholders(feeding) for each network """
    # X : placeholder for the Discriminator (mnist image from either the Generator or the actual distribution)
    X = tf.placeholder(tf.float32, shape=[None, image_size]);
    # z : placeholder for the Generator (white noise from the distribution of real data)
    z = tf.placeholder(tf.float32, shape=[None, noise_size]);
    # training : True => drop out / False => drop out X
    training = tf.placeholder_with_default(False, shape=(), name="training");
    dropout_ratio = 0.5;

    """ Set the parameters for the Generator : Initialized by N(0, 0.01)
        -  noise_size  ->   n_hidden -> image_size(mnist image size)
               128     ->    (1,2,3)     ->      784   
    """
    with tf.name_scope("generator"):
        G_W1 = tf.Variable(tf.random_normal([noise_size, n_hidden1], stddev=0.01), name="hidden1_weight");
        G_b1 = tf.Variable(tf.zeros([n_hidden1]), name="hidden1_bias");
        G_W2 = tf.Variable(tf.random_normal([n_hidden1, n_hidden2], stddev=0.01), name="hidden2_weight");
        G_b2 = tf.Variable(tf.zeros([n_hidden2]), name="hidden2_bias");
        G_W3 = tf.Variable(tf.random_normal([n_hidden2, n_hidden3], stddev=0.01), name="hidden3_weight");
        G_b3 = tf.Variable(tf.zeros([n_hidden3]), name="hidden3_bias");
        G_W4 = tf.Variable(tf.random_normal([n_hidden3, image_size], stddev=0.01), name="output_weight");
        G_b4 = tf.Variable(tf.zeros([image_size]), name="output_bias");



    """ Set the parameters for the Discriminator : Initialized by N(0, 0.01)
        -  image_size(mnist image size)  ->   n_hidden ->    output
                              784        ->    (3,2,1)    ->      1 
        - Here, the output is the probability that the input image comes from the actual distribution of data  
    """
    with tf.name_scope("discriminator"):
        D_W1 = tf.Variable(tf.random_normal([image_size, n_hidden3], stddev=0.01), name="hidden1_weight");
        D_b1 = tf.Variable(tf.zeros([n_hidden3]), name="hidden1_bias");
        D_W2 = tf.Variable(tf.random_normal([n_hidden3, n_hidden2], stddev=0.01), name="hidden2_weight");
        D_b2 = tf.Variable(tf.zeros([n_hidden2]), name="hidden2_bias");
        D_W3 = tf.Variable(tf.random_normal([n_hidden2, n_hidden1], stddev=0.01), name="hidden3_weight");
        D_b3 = tf.Variable(tf.zeros([n_hidden1]), name="hidden3_bias");
        D_W4 = tf.Variable(tf.random_normal([n_hidden1, noise_size], stddev=0.01), name="output_weight");
        D_b4 = tf.Variable(tf.zeros([1]), name="output_bias");



    """
    Make the function of the Generator G
     - input X : white noise 
     - output  : (MNIST data) image generated by the input X
    """
    def Generator(X):
        hidden1 = tf.nn.leaky_relu(tf.matmul(X, G_W1)+G_b1);
        hidden2 = tf.nn.leaky_relu(tf.matmul(hidden1, G_W2) + G_b2);
        hidden3 = tf.nn.leaky_relu(tf.matmul(hidden2, G_W3) + G_b3);
        output = tf.matmul(hidden3, G_W4) + G_b4;
        generated_image = tf.nn.sigmoid(output);

        return generated_image;

    """
    Make the function of the Discriminator
     - input X : (MNIST data) image 
     - output  : discriminate whether the input image comes from the actual distribution of data
            1) predicted_value : True(1) / Fake(0)
            2) logits : output value before sigmoid  
    """
    def Discriminator(X):
        hidden1 = tf.nn.leaky_relu(tf.matmul(X, D_W1) + D_b1);
        hidden1_drop = tf.layers.dropout(hidden1, dropout_ratio, training=training);

        hidden2 = tf.nn.leaky_relu(tf.matmul(hidden1_drop, D_W2) + D_b2);
        hidden2_drop = tf.layers.dropout(hidden2, dropout_ratio, training=training);

        hidden3 = tf.nn.leaky_relu(tf.matmul(hidden2_drop, D_W3) + D_b3);
        hidden3_drop = tf.layers.dropout(hidden3, dropout_ratio, training=training);
        logits = tf.matmul(hidden3_drop, D_W4) + D_b4;
        predicted_value = tf.sigmoid(logits);

        return predicted_value, logits;


    # Make a generator
    G = Generator(z);

    # Make a discriminator
    # D_real = D(x),    D_fake = D(G(z))
    D_real, D_real_logits = Discriminator(X);
    D_fake, D_fake_logits = Discriminator(G);


    """
    Goal : min_{G}max_{D}V(D,G)
           V(D, G) = log(D(x)) + log(1-D(G(z))) 
           Here, x is sampled from the real distribution
                 z is sampled from the noise distribution
                 => G(z) : fake data
           In practice, we use sampled data to compute the expectation
    
    Note that an optimizer is used to 'minimize' loss. 
    Thus, for D, we minimize -V(D,G) = -log(D(x)) - log(1-D(G(z)))
    
    However, G is a poor generator at first.
    Thus D can discriminate fake data generated by G easily.
    i.e D(G(z)) is close to 0
    Thus grad(log(1-D(G(z))) = 1/(1-D(G(Z))grad(G) is close to grad(G) 
    Moreover, the size of the gradient for G_params is very small   
    Thus the gradient descent method is bad.
    On the other hand, grad(log(D(G(z))) = 1/D(G(z))grad(G).
    Since D(G(z)) is close to 0, 1/D(G(z))grad(G) has appropriate size.
    Thus, for G, we minimize -V'(D,G) = -log(D(G(z))
        : minimize log(1-D(G(z)) 
          <=> maximize log(D(G(z))
          <=> minimize -log(D(G(z))
    =========================================================================
    <About some code >
    1. tf.nn.sigmoid_cross_with_logits(logits=x, labels=z)
        = -z*log(sigmoid(x)) - (1-z)*log(1-sigmoid(x))
    =========================================================================
    <Discriminator loss>
      : d_loss = -log(D(x)) - log(D(G(z))) 
               = d_loss_fake + d_loss_real
    1. d_loss_real = Sigmoid_entropy(D_real_logits, [1])
                   = -log(sigmoid(D_real_logits)) since (1-z)=(1-1) term is gone
                   = -log(D_real)
                   = -logD(X) 
    
    2. d_loss_fake = Sigmoid_entropy(D_fake_logits, [0])
                   = -log(1-sigmoid(D_fake_logits))
                   = -log(1-D_fake)
                   = -log(1-D(G(z))
    =========================================================================
    <Generator loss>
      : g_loss = Sigmoid_entropy(D_fake_logits, [1])
               = -log(sigmoid(D_fake_logits))
               = -log(D_fake)
               = -log(D(G(Z))
    =========================================================================   
    """
    with tf.name_scope("loss"):
        d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(
            logits=D_real_logits, labels=tf.ones_like(D_real_logits)));

        d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(
            logits=D_fake_logits, labels=tf.zeros_like(D_fake_logits)));
        d_loss = tf.add(d_loss_real, d_loss_fake, name="d_loss");

        g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(
            logits=D_fake_logits, labels=tf.ones_like(D_fake_logits)), name="g_loss");




    total_variables = tf.trainable_variables();
    d_variables = [var for var in total_variables if "discriminator" in var.name];
    g_variables = [var for var in total_variables if "generator" in var.name];

    #d_variables = [D_W1, D_b1, D_W2, D_b2];
    #g_variables = [G_W1, G_b1, G_W2, G_b2];

    with tf.name_scope("train"):
        d_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.5, beta2=0.999);
        g_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.5, beta2=0.999);
        d_training = d_optimizer.minimize(d_loss, var_list=d_variables);
        g_training = g_optimizer.minimize(g_loss, var_list=g_variables);



    """ Train the network """
    init = tf.global_variables_initializer();
    saver = tf.train.Saver();

    list_d_loss = [];
    list_g_loss = [];

    if not os.path.exists(model_path):
        os.makedirs(model_path);

    if not os.path.exists(fig_path):
        os.makedirs(fig_path);

    d_loss_val=0.;
    g_loss_val=0.;

    with tf.Session() as sess:
        init.run();
        # num_epoch=200
        for i in range(num_epochs):

            for j in range(batch_num):
                x_batch, _ = mnist.train.next_batch(batch_size);
                noise_batch = np.random.normal(size=[batch_size, noise_size]);
                _, d_loss_val = sess.run([d_training, d_loss],
                                         feed_dict={training: True, X: x_batch, z: noise_batch});
                _, g_loss_val = sess.run([g_training, g_loss],
                                         feed_dict={z: noise_batch});


            list_d_loss.append(d_loss_val);
            list_g_loss.append(g_loss_val);
            # Print out g_loss and d_loss
            print("{}-th epoch     D loss: {:.4f}    G loss: {:.4f}".format(
                    i, d_loss_val, g_loss_val
                    ))

            # Save images
            noise_generator = np.random.normal(size=[64, noise_size]);
            samples = sess.run(G, feed_dict={z: noise_generator});
            fig = plot_generated_mnist_images(samples);
            plt.savefig(fig_path + str(i) + ".png", bbox_inches='tight');
            plt.close(fig);

            # Save the model
            saver.save(sess, model_path + "model_" + str(i) + ".ckpt");
            # print("Save the {}-th model".format(i));

        saver.save(sess, model_path+"Final_GAN.ckpt");







def GAN_GENERATE_MNIST():

    image_size = 28 * 28;  # the size of an image generated(or real data == mnist image)
    n_hidden1 = 256;  # the number of neurons in a hidden layer
    n_hidden2 = 512;
    n_hidden3 = 1024;
    noise_size = 128;  # the size of input noise on the generator

    learning_rate = 0.0002;  # learning rate for an optimizer

    """ Set the placeholders(feeding) for each network """
    # X : placeholder for the Discriminator (mnist image from either the Generator or the actual distribution)
    X = tf.placeholder(tf.float32, shape=[None, image_size]);
    # z : placeholder for the Generator (white noise from the distribution of real data)
    z = tf.placeholder(tf.float32, shape=[None, noise_size]);
    # training : True => drop out / False => drop out X
    training = tf.placeholder_with_default(False, shape=(), name="training");
    dropout_ratio = 0.5;

    """ Set the parameters for the Generator : Initialized by N(0, 0.01)
        -  noise_size  ->   n_hidden -> image_size(mnist image size)
               128     ->    (1,2,3)     ->      784   
    """
    with tf.name_scope("generator"):
        G_W1 = tf.Variable(tf.random_normal([noise_size, n_hidden1], stddev=0.01), name="hidden1_weight");
        G_b1 = tf.Variable(tf.zeros([n_hidden1]), name="hidden1_bias");
        G_W2 = tf.Variable(tf.random_normal([n_hidden1, n_hidden2], stddev=0.01), name="hidden2_weight");
        G_b2 = tf.Variable(tf.zeros([n_hidden2]), name="hidden2_bias");
        G_W3 = tf.Variable(tf.random_normal([n_hidden2, n_hidden3], stddev=0.01), name="hidden3_weight");
        G_b3 = tf.Variable(tf.zeros([n_hidden3]), name="hidden3_bias");
        G_W4 = tf.Variable(tf.random_normal([n_hidden3, image_size], stddev=0.01), name="output_weight");
        G_b4 = tf.Variable(tf.zeros([image_size]), name="output_bias");

    """ Set the parameters for the Discriminator : Initialized by N(0, 0.01)
        -  image_size(mnist image size)  ->   n_hidden ->    output
                              784        ->    (3,2,1)    ->      1 
        - Here, the output is the probability that the input image comes from the actual distribution of data  
    """
    with tf.name_scope("discriminator"):
        D_W1 = tf.Variable(tf.random_normal([image_size, n_hidden3], stddev=0.01), name="hidden1_weight");
        D_b1 = tf.Variable(tf.zeros([n_hidden3]), name="hidden1_bias");
        D_W2 = tf.Variable(tf.random_normal([n_hidden3, n_hidden2], stddev=0.01), name="hidden2_weight");
        D_b2 = tf.Variable(tf.zeros([n_hidden2]), name="hidden2_bias");
        D_W3 = tf.Variable(tf.random_normal([n_hidden2, n_hidden1], stddev=0.01), name="hidden3_weight");
        D_b3 = tf.Variable(tf.zeros([n_hidden1]), name="hidden3_bias");
        D_W4 = tf.Variable(tf.random_normal([n_hidden1, noise_size], stddev=0.01), name="output_weight");
        D_b4 = tf.Variable(tf.zeros([1]), name="output_bias");

    """
    Make the function of the Generator G
     - input X : white noise 
     - output  : (MNIST data) image generated by the input X
    """

    def Generator(X):
        hidden1 = tf.nn.leaky_relu(tf.matmul(X, G_W1) + G_b1);
        hidden2 = tf.nn.leaky_relu(tf.matmul(hidden1, G_W2) + G_b2);
        hidden3 = tf.nn.leaky_relu(tf.matmul(hidden2, G_W3) + G_b3);
        output = tf.matmul(hidden3, G_W4) + G_b4;
        generated_image = tf.nn.sigmoid(output);

        return generated_image;

    """
    Make the function of the Discriminator
     - input X : (MNIST data) image 
     - output  : discriminate whether the input image comes from the actual distribution of data
            1) predicted_value : True(1) / Fake(0)
            2) logits : output value before sigmoid  
    """

    def Discriminator(X):
        hidden1 = tf.nn.leaky_relu(tf.matmul(X, D_W1) + D_b1);
        hidden1_drop = tf.layers.dropout(hidden1, dropout_ratio, training=training);

        hidden2 = tf.nn.leaky_relu(tf.matmul(hidden1_drop, D_W2) + D_b2);
        hidden2_drop = tf.layers.dropout(hidden2, dropout_ratio, training=training);

        hidden3 = tf.nn.leaky_relu(tf.matmul(hidden2_drop, D_W3) + D_b3);
        hidden3_drop = tf.layers.dropout(hidden3, dropout_ratio, training=training);
        logits = tf.matmul(hidden3_drop, D_W4) + D_b4;
        predicted_value = tf.sigmoid(logits);

        return predicted_value, logits;

    # Make a generator
    G = Generator(z);

    # Make a discriminator
    # D_real = D(x),    D_fake = D(G(z))
    D_real, D_real_logits = Discriminator(X);
    D_fake, D_fake_logits = Discriminator(G);

    """
    Goal : min_{G}max_{D}V(D,G)
           V(D, G) = log(D(x)) + log(1-D(G(z))) 
           Here, x is sampled from the real distribution
                 z is sampled from the noise distribution
                 => G(z) : fake data
           In practice, we use sampled data to compute the expectation

    Note that an optimizer is used to 'minimize' loss. 
    Thus, for D, we minimize -V(D,G) = -log(D(x)) - log(1-D(G(z)))

    However, G is a poor generator at first.
    Thus D can discriminate fake data generated by G easily.
    i.e D(G(z)) is close to 0
    Thus grad(log(1-D(G(z))) = 1/(1-D(G(Z))grad(G) is close to grad(G) 
    Moreover, the size of the gradient for G_params is very small   
    Thus the gradient descent method is bad.
    On the other hand, grad(log(D(G(z))) = 1/D(G(z))grad(G).
    Since D(G(z)) is close to 0, 1/D(G(z))grad(G) has appropriate size.
    Thus, for G, we minimize -V'(D,G) = -log(D(G(z))
        : minimize log(1-D(G(z)) 
          <=> maximize log(D(G(z))
          <=> minimize -log(D(G(z))
    =========================================================================
    <About some code >
    1. tf.nn.sigmoid_cross_with_logits(logits=x, labels=z)
        = -z*log(sigmoid(x)) - (1-z)*log(1-sigmoid(x))
    =========================================================================
    <Discriminator loss>
      : d_loss = -log(D(x)) - log(D(G(z))) 
               = d_loss_fake + d_loss_real
    1. d_loss_real = Sigmoid_entropy(D_real_logits, [1])
                   = -log(sigmoid(D_real_logits)) since (1-z)=(1-1) term is gone
                   = -log(D_real)
                   = -logD(X) 

    2. d_loss_fake = Sigmoid_entropy(D_fake_logits, [0])
                   = -log(1-sigmoid(D_fake_logits))
                   = -log(1-D_fake)
                   = -log(1-D(G(z))
    =========================================================================
    <Generator loss>
      : g_loss = Sigmoid_entropy(D_fake_logits, [1])
               = -log(sigmoid(D_fake_logits))
               = -log(D_fake)
               = -log(D(G(Z))
    =========================================================================   
    """
    with tf.name_scope("loss"):
        d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(
            logits=D_real_logits, labels=tf.ones_like(D_real_logits)));

        d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(
            logits=D_fake_logits, labels=tf.zeros_like(D_fake_logits)));
        d_loss = tf.add(d_loss_real, d_loss_fake, name="d_loss");

        g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(
            logits=D_fake_logits, labels=tf.ones_like(D_fake_logits)), name="g_loss");

    total_variables = tf.trainable_variables();
    d_variables = [var for var in total_variables if "discriminator" in var.name];
    g_variables = [var for var in total_variables if "generator" in var.name];

    # d_variables = [D_W1, D_b1, D_W2, D_b2];
    # g_variables = [G_W1, G_b1, G_W2, G_b2];

    with tf.name_scope("train"):
        d_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.5, beta2=0.999);
        g_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.5, beta2=0.999);
        d_training = d_optimizer.minimize(d_loss, var_list=d_variables);
        g_training = d_optimizer.minimize(g_loss, var_list=g_variables);



    """ Generate with the trained model"""
    init = tf.global_variables_initializer();
    saver = tf.train.Saver();



    data = "MNIST/"
    path = "./GAN/myGAN/" + data;
    model_path = path + "model/";
    model = model_path+"Final_GAN.ckpt";


    with tf.Session() as sess:
        init.run();

        saver.restore(sess, model);

        for i in range(10):
            noise_generator = np.random.normal(size=[64, noise_size]);
            samples = sess.run(G, feed_dict={z: noise_generator});
            fig = plot_generated_mnist_images(samples);


        plt.show();








































if __name__ == "__main__":
    print("My GAN");
    GAN_TRAIN_MNIST();
    #GAN_GENERATE_MNIST();